s3/emr support for ivory
========================

### Goal

Support a usage of ivory where S3 is used as a file system for an
ivory repository where any processing (ingest, extract, validate) can
be done vie ephemeral EMR clusters.


### Constraints

This must be done in a way that is somewhat efficient, the consequence
of this is that it may preclude directly reading and writing to S3 and
instead using hdfs + distcp to perform operations on the cluster and
sync back.


### Basic behaviour

We can classify ivory work into 3 categories:
 1. Meta-data (dictionary, stores etc...)
 2. Planning (Working out inputs for jobs etc...)
 3. Batch processing (Doing ingest, snapshot, etc...)

Currently all of these only work on HDFS, but we want to extends this
to work in a hybrid environment where (1) and (2) are performed
directly on S3 and (3) is done on a hadoop cluster.


### Implementation


#### Meta-data

This should be fairly straight forward for meta-data, and significant progress
has already been, but the basic design goal is to use `mundane-store` to manage
the differences between underlying implementations. The one outstanding point
is approriate locking mechanisms for `S3` (further discussion below)


#### Planning

This will require significant work. Currently all the planning is tied into
HDFS and `ivory-storage`. To get a maintainable multiple backend support for
ivory, we need to:
 - Convert all of the path searching and selecting code to be pure code working in terms
   of `mundane.io.FilePath` instead of HDFS path.
 - Build out separate path traversal enginges for S3 and HDFS (perhaps this can be
   done in terms of `mundane-store` as well, but I am unsure how sophisticated it
   needs to be in terms of partial directories trees which doesn't map will to store).
 - Rework all the existing code to use this "Planner".


#### Batching

This will require some investigation into read / write performance, to and from S3.
Based on previous experience the default position is that we could read directly from
S3 but would have to write to HDFS.

Using ingest as the example, we should hack together a small test app that would let us
ingest 10GB using the standard hadoop read/write tools:
 - read hdfs -> write hdfs
 - read s3 -> write hdfs
 - read s3 -> write s3

Depending on the performance characteristics of this test, we would then want to implement
a mechanism that synced or read just the minimal set of data (determined by planning phase),
runs job on temporary cluster and syncs data back to s3.
